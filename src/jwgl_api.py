#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¼ºæ™ºæ•™åŠ¡ç³»ç»Ÿ APIæ¥å£
ä¸»è¦åŠŸèƒ½ï¼šè·å–ä¸ªäººä¿¡æ¯ã€è¯¾ç¨‹è¡¨ã€æˆç»©ã€è€ƒè¯•å®‰æ’ç­‰
"""

import requests
from typing import Dict, Any, List, Optional, Union
import json
from datetime import datetime
import logging
import re
from bs4 import BeautifulSoup

try:
    from .login_manager import LoginManager
    from .session_manager import SessionManager
except ImportError:
    from login_manager import LoginManager
    from session_manager import SessionManager


class JwglAPI:
    """
    å¼ºæ™ºæ•™åŠ¡ç³»ç»Ÿ APIæ¥å£ç±»
    
    ä½¿ç”¨å·²ç™»å½•çš„sessionè¿›è¡Œå„ç§æ•™åŠ¡ä¿¡æ¯æŸ¥è¯¢
    æ”¯æŒä¼ å…¥ requests.Session æˆ– SessionManager
    """
    
    def __init__(self, session: Union[requests.Session, SessionManager] = None, 
                 base_url: str = "http://58.20.60.39:8099"):
        """
        åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        
        Args:
            session: å·²ç™»å½•çš„requests.Sessionå¯¹è±¡æˆ–SessionManagerå®ä¾‹
            base_url: æ•™åŠ¡ç³»ç»ŸåŸºç¡€URL
        """
        self.base_url = base_url.rstrip('/')
        self.logger = logging.getLogger(__name__)
        
        if isinstance(session, SessionManager):
            self.session_manager = session
            self.session = session.session
            self._use_session_manager = True
        elif isinstance(session, requests.Session):
            self.session = session
            self.session_manager = None
            self._use_session_manager = False
        else:
            # åˆ›å»ºé»˜è®¤çš„SessionManager
            self.session_manager = SessionManager(base_url=base_url)
            self.session = self.session_manager.session
            self._use_session_manager = True
            
        self.user_info = {}
    
    def _request(self, method: str, url: str, **kwargs) -> requests.Response:
        """
        å‘èµ·HTTPè¯·æ±‚çš„é€šç”¨æ–¹æ³•
        
        Args:
            method: HTTPæ–¹æ³•
            url: è¯·æ±‚URL
            **kwargs: requestså‚æ•°
            
        Returns:
            Responseå¯¹è±¡
        """
        if self._use_session_manager and self.session_manager:
            # ä½¿ç”¨SessionManagerå‘èµ·è¯·æ±‚ï¼ˆè‡ªåŠ¨å¤„ç†ä¼šè¯ï¼‰
            return self.session_manager.request(method, url, **kwargs)
        else:
            # ä½¿ç”¨åŸå§‹sessionå‘èµ·è¯·æ±‚
            if not url.startswith('http'):
                url = f"{self.base_url}{url}"
            
            # è®¾ç½®é»˜è®¤è¯·æ±‚å¤´
            headers = kwargs.get('headers', {})
            default_headers = {
                'Referer': f"{self.base_url}/jsxsd/framework/xsMain.jsp",
                'User-Agent': self.session.headers.get('User-Agent', 'Mozilla/5.0')
            }
            default_headers.update(headers)
            kwargs['headers'] = default_headers
            
            return self.session.request(method, url, **kwargs)
    
    def get_user_info(self) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·ä¸ªäººä¿¡æ¯
        
        Returns:
            ç”¨æˆ·ä¿¡æ¯å­—å…¸
        """
        try:
            # è®¿é—®ä¸ªäººä¿¡æ¯é¡µé¢
            response = self._request('GET', '/jsxsd/grxx/xsxx')
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            user_info = {}
            
            # è§£æå­¦ç±å¡ç‰‡è¡¨æ ¼
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    # å¤„ç†é™¢ç³»ã€ä¸“ä¸šã€ç­çº§ã€å­¦å·è¡Œ
                    text = row.get_text(strip=True)
                    if 'é™¢ç³»ï¼š' in text and 'ä¸“ä¸šï¼š' in text:
                        # è§£æï¼šé™¢ç³»ï¼šæŠ¤ç†å­¦é™¢ | ä¸“ä¸šï¼šæŠ¤ç†å­¦ | å­¦åˆ¶ï¼š4 | ç­çº§ï¼š23æœ¬æŠ¤ç†4ç­ | å­¦å·ï¼š12023050204013
                        parts = text.split('|') if '|' in text else row.get_text('|').split('|')
                        for part in parts:
                            if 'ï¼š' in part:
                                k, v = part.split('ï¼š', 1)
                                user_info[k.strip()] = v.strip()
                    
                    # å¤„ç†æ ‡å‡†çš„é”®å€¼å¯¹è¡Œ
                    cells = row.find_all(['td', 'th'])
                    
                    # å§“åã€æ€§åˆ«ã€å§“åæ‹¼éŸ³ç­‰è¡Œ
                    if len(cells) >= 6:
                        # å¤„ç†: å§“å | ä»˜ä½³é¹­ | æ€§åˆ« | å¥³ | å§“åæ‹¼éŸ³ | fujialu
                        for i in range(0, len(cells)-1, 2):
                            key = cells[i].get_text(strip=True).replace('ï¼š', '').replace(':', '')
                            if i+1 < len(cells):
                                value = cells[i+1].get_text(strip=True)
                                if key and value and key in ['å§“å', 'æ€§åˆ«', 'å§“åæ‹¼éŸ³', 'å‡ºç”Ÿæ—¥æœŸ', 'å©šå¦', 'æœ¬äººç”µè¯',
                                                             'ä¸“ä¸šæ–¹å‘', 'æ”¿æ²»é¢è²Œ', 'ç±è´¯', 'å…¥å…šå›¢æ—¶é—´', 'æ°‘æ—',
                                                             'å­¦ä¹ å½¢å¼', 'å­¦ä¹ å±‚æ¬¡', 'å¤–è¯­ç§ç±»', 'å®¶åº­ç°ä½å€',
                                                             'ä¸‹è½¦ç«è½¦ç«™', 'é‚®æ”¿ç¼–ç ', 'å®¶åº­ç”µè¯', 'è”ç³»äºº',
                                                             'å…¥å­¦æ—¥æœŸ', 'æ¯•ä¸šæ—¥æœŸ', 'å…¥å­¦è€ƒå·', 'èº«ä»½è¯ç¼–å·']:
                                    user_info[key] = value
                    # å¤„ç†ç®€å•çš„é”®å€¼å¯¹
                    elif len(cells) == 4:
                        # å¤„ç†: å…¥å­¦æ—¥æœŸ | 202309 | æ¯•ä¸šæ—¥æœŸ | 
                        for i in range(0, len(cells)-1, 2):
                            key = cells[i].get_text(strip=True).replace('ï¼š', '').replace(':', '')
                            if i+1 < len(cells):
                                value = cells[i+1].get_text(strip=True)
                                if key and value and any('ä¸€' <= c <= 'é¿¿' for c in key):
                                    user_info[key] = value
            
            # ç¼“å­˜ç”¨æˆ·ä¿¡æ¯
            self.user_info = user_info
            
            self.logger.info(f"è·å–ç”¨æˆ·ä¿¡æ¯æˆåŠŸ: {len(user_info)}ä¸ªå­—æ®µ")
            return user_info
            
        except Exception as e:
            self.logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def get_schedule(self, year: str = None, semester: str = None) -> List[Dict[str, Any]]:
        """
        è·å–è¯¾ç¨‹è¡¨ï¼ˆæŒ‰å‘¨æ‹†åˆ†æˆç‹¬ç«‹çš„è¯¾ç¨‹å•å…ƒï¼‰
        
        Args:
            year: å­¦å¹´ï¼Œå¦‚"2023-2024"
            semester: å­¦æœŸï¼Œå¦‚"1"æˆ–"2"
            
        Returns:
            æŒ‰å‘¨æ‹†åˆ†çš„è¯¾ç¨‹å•å…ƒåˆ—è¡¨ï¼Œæ¯ä¸ªå•å…ƒä»£è¡¨æŸä¸€å‘¨çš„ä¸€æ¬¡å®Œæ•´è¯¾ç¨‹
            ä¿æŒå®Œæ•´çš„èŠ‚æ¬¡æ ¼å¼ï¼ˆå¦‚ 09-10-11èŠ‚ï¼‰
        """
        try:
            url = '/jsxsd/xskb/xskb_list.do'
            
            # é¦–å…ˆé€šè¿‡GETè¯·æ±‚è·å–è¯¾ç¨‹è¡¨é¡µé¢å’Œéšè—å­—æ®µ
            response = self._request('GET', url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ„å»ºå‚æ•°
            data = {
                'cj0701id': '',
                'zc': '',  # å‘¨æ¬¡
                'demo': '',
                'sfFD': '1'  # æ”¾å¤§æ˜¾ç¤º
            }
            
            # è®¾ç½®å­¦æœŸå‚æ•°
            if year and semester:
                data['xnxq01id'] = f"{year}-{semester}"
            elif year:
                data['xnxq01id'] = year
            else:
                # è·å–é»˜è®¤å­¦æœŸ
                semester_select = soup.find('select', {'name': 'xnxq01id'})
                if semester_select:
                    selected_option = semester_select.find('option', selected=True)
                    if selected_option:
                        data['xnxq01id'] = selected_option.get('value', '')
            
            # è·å–æ‰€æœ‰éšè—å­—æ®µ - è¿™äº›æ˜¯å¿…éœ€çš„
            hidden_inputs = soup.find_all('input', type='hidden')
            for hidden_input in hidden_inputs:
                name = hidden_input.get('name')
                value = hidden_input.get('value', '')
                if name:
                    if name in data:
                        # å¦‚æœå·²å­˜åœ¨ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                        if isinstance(data[name], list):
                            data[name].append(value)
                        else:
                            data[name] = [data[name], value]
                    else:
                        data[name] = value
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded',
                'Referer': f"{self.base_url}/jsxsd/xskb/xskb_list.do"
            }
            
            # å‘é€POSTè¯·æ±‚
            response = self._request('POST', url, data=data, headers=headers)
            response.raise_for_status()
            
            print(f"ğŸ” HTTPå“åº”çŠ¶æ€: {response.status_code}")
            print(f"ğŸ” å“åº”å†…å®¹é•¿åº¦: {len(response.text)}")
            
            # è§£æè¯¾ç¨‹è¡¨HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾è¯¾ç¨‹è¡¨æ ¼ - åŸºäºMCPåˆ†æçš„å®é™…ç»“æ„
            schedule_table = soup.find('table', {'id': 'kbtable'})
            
            if not schedule_table:
                self.logger.warning("æœªæ‰¾åˆ°è¯¾ç¨‹è¡¨æ•°æ®è¡¨æ ¼")
                return []
            
            courses = []
            rows = schedule_table.find_all('tr')
            
            # é¢„å®šä¹‰çš„æ—¶é—´æ®µæ˜ å°„ - æ ¹æ®MCPåˆ†æçš„æ­£ç¡®ç»“æœ
            time_slot_mapping = {
                1: "ä¸€äºŒ",
                2: "ä¸‰å››", 
                3: "äº”å…­",
                4: "ä¸ƒå…«",
                5: "ä¹å",
                6: "åä¸€åäºŒ"
            }
            
            day_names = ['', 'å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
            
            # ä»ç¬¬1è¡Œå¼€å§‹å¤„ç†æ•°æ®è¡Œï¼ˆç¬¬0è¡Œæ˜¯è¡¨å¤´ï¼‰
            for row_idx in range(1, len(rows)):
                if row_idx > 6:  # åªå¤„ç†6è¡Œæ•°æ®ï¼ˆå¯¹åº”6ä¸ªæ—¶é—´æ®µï¼‰
                    break
                    
                row = rows[row_idx]
                cells = row.find_all('td')
                if len(cells) < 2:
                    continue
                
                # ä½¿ç”¨é¢„å®šä¹‰çš„æ—¶é—´æ®µæ˜ å°„
                time_slot = time_slot_mapping.get(row_idx, "æœªçŸ¥")
                
                # å¤„ç†æ¯ä¸€å¤©çš„è¯¾ç¨‹ (ä»ç¬¬1åˆ—å¼€å§‹æ˜¯å‘¨ä¸€)
                for day_idx in range(1, min(len(cells), 8)):
                    cell = cells[day_idx]
                    
                    # ä½¿ç”¨æ˜¾ç¤ºçš„divå†…å®¹
                    visible_div = cell.find('div', class_='kbcontent')
                    if visible_div:
                        cell_text = visible_div.get_text('\n', strip=True)
                    else:
                        cell_text = cell.get_text('\n', strip=True)
                    
                    if not cell_text.strip():
                        continue
                    
                    weekday = day_names[day_idx]
                    
                    # è§£æå•å…ƒæ ¼ä¸­çš„è¯¾ç¨‹ - å¤„ç†ç”±---------------------åˆ†éš”çš„å¤šä¸ªè¯¾ç¨‹
                    cell_courses = self._parse_course_from_cell(cell_text)
                    
                    for course in cell_courses:
                        course.update({
                            'time_slot': time_slot,  # ä½¿ç”¨æ­£ç¡®çš„æ—¶é—´æ®µ
                            'day_of_week': day_idx,
                            'day_name': weekday
                        })
                        courses.append(course)
            
            self.logger.info(f"è·å–è¯¾ç¨‹è¡¨æˆåŠŸï¼Œå…±{len(courses)}é—¨è¯¾ç¨‹")
            
            # æŒ‰å‘¨æ‹†åˆ†æˆè¯¾ç¨‹å•å…ƒ
            semester_id = data.get('xnxq01id', '')
            schedule_units = self._split_courses_by_weeks(courses, semester_id)
            self.logger.info(f"æŒ‰å‘¨æ‹†åˆ†åï¼Œå…±{len(schedule_units)}ä¸ªè¯¾ç¨‹å•å…ƒ")
            return schedule_units
            
        except Exception as e:
            self.logger.error(f"è·å–è¯¾ç¨‹è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def _parse_course_from_cell(self, cell_content: str) -> List[Dict[str, Any]]:
        """
        è§£æè¯¾ç¨‹è¡¨å•å…ƒæ ¼å†…å®¹ï¼Œå¤„ç†ç”±---------------------åˆ†éš”çš„å¤šä¸ªè¯¾ç¨‹
        åŸºäºMCPåˆ†æçš„çœŸå®ç»“æ„è¿›è¡Œè§£æ
        
        Args:
            cell_content: å•å…ƒæ ¼çš„æ–‡æœ¬å†…å®¹
            
        Returns:
            è§£æåçš„è¯¾ç¨‹åˆ—è¡¨
        """
        courses = []
        
        if not cell_content or not cell_content.strip():
            return courses
        
        # æŒ‰ --------------------- åˆ†å‰²è¯¾ç¨‹
        course_blocks = cell_content.split('---------------------')
        
        for block in course_blocks:
            block = block.strip()
            if not block:
                continue
            
            # æŒ‰è¡Œåˆ†å‰²
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            
            if len(lines) < 1:  # è‡³å°‘è¦æœ‰è¯¾ç¨‹å
                continue
                
            course_info = {
                'course_name': '',
                'teacher': '',
                'weeks': '',
                'time_periods': '',
                'classroom': '',
                'raw_info': block
            }
            
            # ç¬¬1è¡Œé€šå¸¸æ˜¯è¯¾ç¨‹åç§°
            course_info['course_name'] = lines[0]
            
            # ç¬¬2è¡Œé€šå¸¸æ˜¯æ•™å¸ˆå§“å
            if len(lines) > 1:
                course_info['teacher'] = lines[1]
            
            # ç¬¬3è¡Œé€šå¸¸åŒ…å«å‘¨æ¬¡å’ŒèŠ‚æ¬¡ä¿¡æ¯ï¼Œå¦‚ï¼š"1-3,6,11-12(å‘¨)[01-02èŠ‚]"
            if len(lines) > 2:
                time_info = lines[2]
                
                # æå–å‘¨æ¬¡ä¿¡æ¯
                weeks_match = re.search(r'([0-9,-]+)\(å‘¨\)', time_info)
                if weeks_match:
                    course_info['weeks'] = weeks_match.group(1)
                
                # æå–èŠ‚æ¬¡ä¿¡æ¯
                periods_match = re.search(r'\[([0-9-]+)èŠ‚\]', time_info)
                if periods_match:
                    course_info['time_periods'] = periods_match.group(1)
            
            # ç¬¬4è¡Œé€šå¸¸æ˜¯æ•™å®¤
            if len(lines) > 3:
                course_info['classroom'] = lines[3]
            
            # åªæœ‰æœ‰è¯¾ç¨‹åçš„æ‰æ·»åŠ 
            if course_info['course_name']:
                courses.append(course_info)
        
        return courses
    
    def get_grades(self, year: str = None, semester: str = None, course_name: str = None, course_nature: str = None, show_all: bool = True, use_post: bool = True) -> Dict[str, Any]:
        """
        è·å–æˆç»©ä¿¡æ¯
        
        Args:
            year: å­¦å¹´ï¼Œå¦‚"2023-2024"
            semester: å­¦æœŸï¼Œå¦‚"1"æˆ–"2" 
            course_name: è¯¾ç¨‹åç§°ï¼ˆæ¨¡ç³Šæœç´¢ï¼‰
            course_nature: è¯¾ç¨‹æ€§è´¨ï¼Œå¯é€‰å€¼ï¼š
                        - "01" æˆ– "å…¬å…±è¯¾"
                        - "02" æˆ– "å…¬å…±åŸºç¡€è¯¾"
                        - "03" æˆ– "ä¸“ä¸šåŸºç¡€è¯¾"
                        - "04" æˆ– "ä¸“ä¸šè¯¾"
                        - "05" æˆ– "ä¸“ä¸šé€‰ä¿®è¯¾"
                        - "06" æˆ– "å…¬å…±é€‰ä¿®è¯¾"
                        - "07" æˆ– "å…¶å®ƒ"
            show_all: æ˜¯å¦æ˜¾ç¤ºå…¨éƒ¨æˆç»©ï¼ˆé»˜è®¤True=æ˜¾ç¤ºå…¨éƒ¨æˆç»©ï¼ŒFalse=åªæ˜¾ç¤ºæœ€å¥½æˆç»©ï¼‰
            use_post: æ˜¯å¦ä½¿ç”¨POSTè¯·æ±‚ï¼ˆé»˜è®¤Trueï¼ŒFalseåˆ™ä½¿ç”¨GETï¼‰
                     æ³¨æ„ï¼šGETè¯·æ±‚åªæ”¯æŒkksjå‚æ•°ï¼Œå…¶ä»–å‚æ•°ä¼šè¢«å¿½ç•¥ï¼
                     å¦‚éœ€ä½¿ç”¨å¤šä¸ªç­›é€‰æ¡ä»¶ï¼Œè¯·ä½¿ç”¨POSTè¯·æ±‚
            
        Returns:
            æˆç»©ä¿¡æ¯
        """
        try:
            url = '/jsxsd/kscj/cjcx_list'
            
            # æ„å»ºå‚æ•° - æ ¹æ®å®é™…ç½‘ç»œè¯·æ±‚åˆ†æç»“æœä¼˜åŒ–
            params = {
                'kksj': '',  # å¼€è¯¾æ—¶é—´
                'kcxz': '',  # è¯¾ç¨‹æ€§è´¨
                'kcmc': '',  # è¯¾ç¨‹åç§°
                'xsfs': 'all' if show_all else 'max'  # æ˜¾ç¤ºæ–¹å¼ï¼ˆmax=æ˜¾ç¤ºæœ€å¥½æˆç»©ï¼Œall=æ˜¾ç¤ºå…¨éƒ¨æˆç»©ï¼‰
            }
            
            # å¦‚æœæŒ‡å®šäº†å­¦å¹´å’Œå­¦æœŸï¼Œæ„å»ºkksjå‚æ•°
            if year and semester:
                params['kksj'] = f"{year}-{semester}"
            elif year:
                params['kksj'] = year
                
            # å¦‚æœæŒ‡å®šäº†è¯¾ç¨‹åç§°
            if course_name:
                params['kcmc'] = course_name
                
            # å¦‚æœæŒ‡å®šäº†è¯¾ç¨‹æ€§è´¨
            if course_nature:
                # è¯¾ç¨‹æ€§è´¨ä¸­æ–‡åˆ°ä»£ç çš„æ˜ å°„ï¼ˆå®é™…ä½¿ç”¨01ã€02ç­‰ä»£ç ï¼‰
                nature_map = {
                    'å…¬å…±è¯¾': '01',
                    'å…¬å…±åŸºç¡€è¯¾': '02', 
                    'ä¸“ä¸šåŸºç¡€è¯¾': '03',
                    'ä¸“ä¸šè¯¾': '04',
                    'ä¸“ä¸šé€‰ä¿®è¯¾': '05',
                    'å…¬å…±é€‰ä¿®è¯¾': '06',
                    'å…¶å®ƒ': '07'
                }
                # å¦‚æœä¼ å…¥çš„æ˜¯ä¸­æ–‡ï¼Œè½¬æ¢ä¸ºä»£ç 
                if course_nature in nature_map:
                    params['kcxz'] = nature_map[course_nature]
                else:
                    # å¦åˆ™ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å€¼ï¼ˆå¯èƒ½æ˜¯ä»£ç ï¼‰
                    params['kcxz'] = course_nature
            
            # æ ¹æ®è¯·æ±‚æ–¹å¼å‘é€è¯·æ±‚
            if use_post:
                # POSTè¯·æ±‚ï¼šå‚æ•°åœ¨bodyä¸­
                headers = {
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'Referer': f'{self.base_url}/jsxsd/kscj/cjcx_query'
                }
                response = self._request('POST', url, data=params, headers=headers)
            else:
                # GETè¯·æ±‚ï¼šå‚æ•°åœ¨URLä¸­
                response = self._request('GET', url, params=params)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æˆç»©è¡¨æ ¼ - æ ¹æ®HTMLç»“æ„åˆ†æç»“æœä¼˜åŒ–
            grade_table = soup.find('table', {'id': 'dataList'}) or \
                         soup.find('table', class_='Nsb_r_list Nsb_table') or \
                         soup.find('table', class_='Nsb_r_list')
            
            if not grade_table:
                self.logger.warning("æœªæ‰¾åˆ°æˆç»©æ•°æ®è¡¨æ ¼")
                return {'grades': [], 'error': 'æœªæ‰¾åˆ°æˆç»©æ•°æ®'}
            
            grades = []
            
            # è§£ææˆç»©æ•°æ®è¡Œ
            rows = grade_table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
            
            for row in rows:
                cells = row.find_all('td')
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯"æœªæŸ¥è¯¢åˆ°æ•°æ®"çš„æƒ…å†µ
                if len(cells) == 1 and 'æœªæŸ¥è¯¢åˆ°æ•°æ®' in cells[0].get_text():
                    self.logger.info(f"å­¦æœŸ {params.get('kksj', 'å…¨éƒ¨')} æš‚æ— æˆç»©æ•°æ®")
                    return {
                        'grades': [],
                        'total_count': 0,
                        'year': year,
                        'semester': semester,
                        'message': 'æœªæŸ¥è¯¢åˆ°æ•°æ®'
                    }
                
                # è§£ææˆç»©æ•°æ® - æ ¹æ®HTMLç»“æ„åˆ†æç»“æœä¼˜åŒ–çš„16åˆ—ç»“æ„
                if len(cells) >= 16:
                    # ä½¿ç”¨è¾…åŠ©å‡½æ•°æå–æ¸…æ´çš„æ–‡æœ¬å†…å®¹
                    def extract_clean_text(cell):
                        """Extract clean text from cell, handling links and special formatting"""
                        # å¦‚æœåŒ…å«é“¾æ¥ï¼Œä¼˜å…ˆè·å–é“¾æ¥çš„æ–‡æœ¬å†…å®¹
                        link = cell.find('a')
                        if link:
                            return link.get_text(strip=True)
                        return cell.get_text(strip=True)
                    
                    grade = {
                        'åºå·': extract_clean_text(cells[0]),
                        'å¼€è¯¾å­¦æœŸ': extract_clean_text(cells[1]),
                        'è¯¾ç¨‹ç¼–å·': extract_clean_text(cells[2]),
                        'è¯¾ç¨‹åç§°': extract_clean_text(cells[3]),
                        'æ€»æˆç»©': extract_clean_text(cells[4]),  # å¯èƒ½åŒ…å«é“¾æ¥
                        'æŠ€èƒ½æˆç»©': extract_clean_text(cells[5]),
                        'å¹³æ—¶æˆç»©': extract_clean_text(cells[6]),
                        'å·é¢æˆç»©': extract_clean_text(cells[7]),
                        'æˆç»©æ ‡å¿—': extract_clean_text(cells[8]),
                        'å­¦åˆ†': extract_clean_text(cells[9]),
                        'è€ƒè¯•æ€§è´¨': extract_clean_text(cells[10]),
                        'æ€»å­¦æ—¶': extract_clean_text(cells[11]),
                        'ç»©ç‚¹': extract_clean_text(cells[12]),
                        'è€ƒæ ¸æ–¹å¼': extract_clean_text(cells[13]),
                        'è¯¾ç¨‹å±æ€§': extract_clean_text(cells[14]),
                        'è¯¾ç¨‹æ€§è´¨': extract_clean_text(cells[15])
                    }
                    
                    # ä¸æ·»åŠ é¢å¤–å­—æ®µï¼Œä¿æŒåŸå§‹è¡¨æ ¼åˆ—ç»“æ„
                    grades.append(grade)
            
            self.logger.info(f"è·å–æˆç»©æˆåŠŸï¼Œå…±{len(grades)}é—¨è¯¾ç¨‹")
            
            # ç›´æ¥è¿”å›æˆç»©åˆ—è¡¨ï¼Œä¸åŒ…è£…é¢å¤–ä¿¡æ¯
            return grades
            
        except Exception as e:
            self.logger.error(f"è·å–æˆç»©å¤±è´¥: {str(e)}")
            return {'grades': [], 'error': str(e)}
    
    def get_exam_schedule(self) -> Dict[str, Any]:
        """
        è·å–è€ƒè¯•å®‰æ’
        
        Returns:
            è€ƒè¯•å®‰æ’ä¿¡æ¯
        """
        try:
            url = '/jsxsd/xsks/xsksap_list'
            
            # GETå’ŒPOSTéƒ½æ”¯æŒï¼Œé»˜è®¤ä½¿ç”¨POSTï¼ˆæ›´ç¨³å®šï¼‰
            response = self._request('POST', url, data=params)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾è€ƒè¯•å®‰æ’è¡¨æ ¼ï¼ˆä½¿ç”¨æ­£ç¡®çš„IDï¼‰
            exam_table = soup.find('table', {'id': 'dataList'})
            if not exam_table:
                # å°è¯•ä½¿ç”¨classæŸ¥æ‰¾
                exam_table = soup.find('table', {'class': 'Nsb_r_list Nsb_table'})
            
            if not exam_table:
                self.logger.warning("æœªæ‰¾åˆ°è€ƒè¯•å®‰æ’æ•°æ®")
                return {'exams': [], 'error': 'æœªæ‰¾åˆ°è€ƒè¯•å®‰æ’æ•°æ®'}
            
            exams = []
            
            # è§£æè¡¨å¤´
            header_row = exam_table.find('tr')
            headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
            
            # è§£æè€ƒè¯•æ•°æ®
            rows = exam_table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
            
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= len(headers):
                    exam = {}
                    for i, header in enumerate(headers):
                        if i < len(cells):
                            exam[header] = cells[i].get_text(strip=True)
                    exams.append(exam)
            
            self.logger.info(f"è·å–è€ƒè¯•å®‰æ’æˆåŠŸï¼Œå…±{len(exams)}åœºè€ƒè¯•")
            return {
                'exams': exams,
                'total_count': len(exams)
            }
            
        except Exception as e:
            self.logger.error(f"è·å–è€ƒè¯•å®‰æ’å¤±è´¥: {str(e)}")
            return {'exams': [], 'error': str(e)}
    
    def get_available_semesters(self) -> List[Dict[str, str]]:
        """
        è·å–å¯ç”¨çš„å­¦å¹´å­¦æœŸåˆ—è¡¨
        
        Returns:
            å­¦å¹´å­¦æœŸåˆ—è¡¨
        """
        try:
            # è®¿é—®æˆç»©æŸ¥è¯¢é¡µé¢è·å–å­¦æœŸé€‰é¡¹
            response = self._request('GET', '/jsxsd/kscj/cjcx_list')
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            semesters = []
            
            # æŸ¥æ‰¾å­¦æœŸä¸‹æ‹‰é€‰æ‹©æ¡†
            semester_select = soup.find('select', {'name': 'xnxq01id'})
            
            if semester_select:
                options = semester_select.find_all('option')
                for option in options:
                    value = option.get('value', '')
                    text = option.get_text(strip=True)
                    if value and text:
                        semesters.append({
                            'value': value,
                            'text': text
                        })
            
            self.logger.info(f"è·å–å­¦æœŸåˆ—è¡¨æˆåŠŸï¼Œå…±{len(semesters)}ä¸ªå­¦æœŸ")
            return semesters
            
        except Exception as e:
            self.logger.error(f"è·å–å­¦æœŸåˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def test_connection(self) -> bool:
        """
        æµ‹è¯•è¿æ¥æ˜¯å¦æ­£å¸¸
        
        Returns:
            è¿æ¥æ˜¯å¦æ­£å¸¸
        """
        try:
            response = self._request('GET', '/jsxsd/framework/xsMain.jsp')
            return response.status_code == 200 and 'å­¦ç”Ÿä¸ªäººä¸­å¿ƒ' in response.text
            
        except Exception as e:
            self.logger.error(f"æµ‹è¯•è¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def get_session_info(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰ä¼šè¯ä¿¡æ¯
        
        Returns:
            ä¼šè¯ä¿¡æ¯
        """
        info = {
            'use_session_manager': self._use_session_manager,
            'user_info': self.user_info,
            'base_url': self.base_url
        }
        
        if self._use_session_manager and self.session_manager:
            info.update(self.session_manager.get_session_info())
        
        return info
    
    def _parse_weeks(self, week_str: str) -> List[int]:
        """
        è§£æå‘¨æ¬¡å­—ç¬¦ä¸²ï¼Œè¿”å›æ‰€æœ‰å‘¨æ¬¡çš„åˆ—è¡¨
        ä¾‹å¦‚: "3-5,7" -> [3, 4, 5, 7]
        """
        weeks = []
        if not week_str:
            return weeks
        
        parts = week_str.split(',')
        for part in parts:
            part = part.strip()
            if '-' in part:
                # å¤„ç†èŒƒå›´ï¼Œå¦‚ "3-5"
                start, end = part.split('-')
                weeks.extend(range(int(start), int(end) + 1))
            else:
                # å¤„ç†å•ä¸ªå‘¨æ¬¡ï¼Œå¦‚ "7"
                weeks.append(int(part))
        
        return sorted(weeks)
    
    def _split_courses_by_weeks(self, courses: List[Dict[str, Any]], semester: str = "") -> List[Dict[str, Any]]:
        """
        å°†è¯¾ç¨‹æŒ‰å‘¨æ‹†åˆ†æˆç‹¬ç«‹çš„è¯¾ç¨‹å•å…ƒ
        
        Args:
            courses: åŸå§‹è¯¾ç¨‹åˆ—è¡¨
            semester: å­¦æœŸæ ‡è¯†
            
        Returns:
            æŒ‰å‘¨æ‹†åˆ†çš„è¯¾ç¨‹å•å…ƒåˆ—è¡¨ï¼Œå»æ‰å¤šä½™å­—æ®µ
        """
        all_units = []
        
        for course in courses:
            weeks = self._parse_weeks(course.get('weeks', ''))
            
            # ä¸ºæ¯ä¸ªå‘¨æ¬¡åˆ›å»ºä¸€ä¸ªè¯¾ç¨‹å•å…ƒ
            for week in weeks:
                unit = {
                    'semester': semester,
                    'week': week,
                    'weekday': course.get('day_name', ''),
                    'weekday_num': course.get('day_of_week', 0),
                    'time_slot_name': course.get('time_slot', ''),
                    'periods': course.get('time_periods', ''),  # ä¿æŒå®Œæ•´æ ¼å¼å¦‚ "09-10-11"
                    'course_name': course.get('course_name', ''),
                    'teacher': course.get('teacher', ''),
                    'classroom': course.get('classroom', '')
                    # ä¸åŒ…å« original_weeks, original_periods, raw_info ç­‰å­—æ®µ
                }
                all_units.append(unit)
        
        return all_units
